{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-improvement",
   "metadata": {},
   "source": [
    "# Define Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-harvest",
   "metadata": {},
   "source": [
    "## Basic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample period \n",
    "dt = 2e-9 # 2ns <-> 500 MHz\n",
    "\n",
    "# length of signal 2 relative to signal 1\n",
    "length_factor = 2\n",
    "\n",
    "# number of samples\n",
    "num_samp1 = 8192\n",
    "num_samp2 = length_factor * num_samp1\n",
    "\n",
    "# time\n",
    "time1 = np.arange(0, num_samp1, 1) * dt\n",
    "time2 = np.arange(0, num_samp2, 1) * dt\n",
    "\n",
    "# signal power\n",
    "power = 1\n",
    "\n",
    "# noise_variance\n",
    "noise_variance = 1e2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-journalism",
   "metadata": {},
   "source": [
    "## Signal 1 and Signal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "## signal 1\n",
    "\n",
    "# amplitude signal 1\n",
    "amp1 = np.sqrt(power)\n",
    "\n",
    "# frequency signal 1\n",
    "#freq1 = 66.8945e6 # uncomment to use frequency exactly on a DFFT frequency.\n",
    "freq1 = 50e6\n",
    "\n",
    "s1 = amp1 * np.exp(-1j * 2 * np.pi * freq1 * time1) \n",
    "\n",
    "## signal 2\n",
    "\n",
    "# amplitude signal 2\n",
    "amp2 = np.sqrt(power / length_factor)\n",
    "\n",
    "# frequency signal 2\n",
    "freq2 = freq1\n",
    "\n",
    "s2 = amp2 * np.exp(-1j * 2 * np.pi * freq2 * time2)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(time1, np.real(s1))\n",
    "ax1.set_xlim(time1[0], time1[200])\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.plot(time2, np.real(s2))\n",
    "ax2.set_xlim(time2[0], time2[200])\n",
    "\n",
    "print('Energy signal 1 = %.1f' % (np.vdot(s1, s1).real))\n",
    "print('Energy signal 2 = %.1f' % (np.vdot(s2, s2).real))\n",
    "\n",
    "print('Power signal 1 = %.1f' % (np.vdot(s1, s1).real / num_samp1))\n",
    "print('Power signal 2 = %.1f' % (np.vdot(s2, s2).real / num_samp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-partner",
   "metadata": {},
   "source": [
    "## noisy signal1 and signal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal 1\n",
    "noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, int(np.ceil(num_samp1)))\n",
    "noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "x1 = s1 + noise\n",
    "\n",
    "# signal 2\n",
    "noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, int(np.ceil(num_samp2)))\n",
    "noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "x2 = s2 + noise\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(time1, np.real(x1))\n",
    "ax1.plot(time1, np.real(s1))\n",
    "ax1.set_xlim(time1[0], time1[200])\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.plot(time2, np.real(x2))\n",
    "ax2.plot(time2, np.real(s2))\n",
    "ax2.set_xlim(time2[0], time2[200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-angle",
   "metadata": {},
   "source": [
    "# Baseline - FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "fft1 = np.fft.fftshift(np.fft.fft(x1)) / num_samp1\n",
    "fft2 = np.fft.fftshift(np.fft.fft(x2)) / num_samp2\n",
    "\n",
    "freq1 = np.fft.fftshift(np.fft.fftfreq(int(np.ceil(num_samp1)), dt))\n",
    "freq2 = np.fft.fftshift(np.fft.fftfreq(int(np.ceil(num_samp2)), dt))\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.plot(freq1, abs(fft1)**2)\n",
    "ax1.set_ylim(0, 1.5)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax2.plot(freq2, abs(fft2)**2)\n",
    "ax2.set_ylim(0, 1.5)\n",
    "\n",
    "# get stats\n",
    "N = 2048\n",
    "\n",
    "snr_list1 = []\n",
    "snr_list2 = []\n",
    "for n in range(N):\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, int(np.ceil(num_samp1)))\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "    x1 = s1 + noise\n",
    "\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, int(np.ceil(num_samp2)))\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "    x2 = s2 + noise\n",
    "    \n",
    "    fft1 = np.fft.fftshift(np.fft.fft(x1)) / num_samp1\n",
    "    fft2 = np.fft.fftshift(np.fft.fft(x2)) / num_samp2\n",
    "    \n",
    "    snr_list1.append(np.max(abs(fft1))**2 / np.mean(abs(fft1)**2))\n",
    "    snr_list2.append(np.max(abs(fft2))**2 / np.mean(abs(fft2)**2))\n",
    "\n",
    "#print(np.max(abs(fft1)**2), np.max(abs(fft2))**2)\n",
    "print('Power signal 1 = %.1f' % (np.vdot(s1, s1).real / num_samp1))\n",
    "print('Power signal 2 = %.1f' % (np.vdot(s2, s2).real / num_samp2))\n",
    "\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "hist1 = ax3.hist(snr_list1, 32)\n",
    "#ax3.set_ylim(0, 1.5)\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "hist2 = ax4.hist(snr_list2, 32)\n",
    "\n",
    "print('Mean SNR for signal 1 = %.2f' % np.mean(hist1[1]))\n",
    "print('Mean SNR for signal 2 = %.2f' % np.mean(hist2[1]))\n",
    "print('\\nNote FFT SNR is not equal due to discrete frequency effects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-spirit",
   "metadata": {},
   "source": [
    "# Matched Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "# templates\n",
    "h1 = s1 / (np.sqrt(np.vdot(s1, s1).real * noise_variance))\n",
    "h2 = s2 / (np.sqrt(np.vdot(s2, s2).real * noise_variance))\n",
    "\n",
    "# convolve\n",
    "conv1 = scipy.signal.fftconvolve(h1, x1)\n",
    "conv2 = scipy.signal.fftconvolve(h2, x2)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.plot(abs(conv1))\n",
    "#ax1.set_xlim(num_samp1 * 0.9, num_samp1 * 1.1)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax2.plot(abs(conv2))\n",
    "#ax2.set_ylim(0, 1.5)\n",
    "\n",
    "# get stats\n",
    "N = 2048\n",
    "\n",
    "mf_score_list1 = []\n",
    "mf_score_list2 = []\n",
    "for n in range(N):\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, int(np.ceil(num_samp1)))\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "    x1 = s1 + noise\n",
    "\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, int(np.ceil(num_samp2)))\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "    x2 = s2 + noise\n",
    "    \n",
    "    mf_score_list1.append(np.vdot(h1, x1))\n",
    "    mf_score_list2.append(np.vdot(h2, x2))\n",
    "\n",
    "#print(np.max(abs(fft1)**2), np.max(abs(fft2))**2)\n",
    "print('Power signal 1 = %.1f' % (np.vdot(s1, s1).real / num_samp1))\n",
    "print('Power signal 2 = %.1f' % (np.vdot(s2, s2).real / num_samp2))\n",
    "\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "hist1 = ax3.hist(abs(np.asarray(mf_score_list1)), 32)\n",
    "#ax3.set_ylim(0, 1.5)\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "hist2 = ax4.hist(abs(np.asarray(mf_score_list2)), 32)\n",
    "\n",
    "print('Mean MF score for signal 1 = %.2f' % np.mean(hist1[1]))\n",
    "print('Mean SNR for signal 2 = %.2f' % np.mean(hist2[1]))\n",
    "print('\\nMF filter scores are the same for signals with the same energy but different lengths.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-elephant",
   "metadata": {},
   "source": [
    "## Add independent WGN to each channel. The array with many channels has lower SNR per channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_small_noise = []\n",
    "signals_large_noise = []\n",
    "\n",
    "for n in range(signals_small.shape[0]):\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_small_noise.append(signals_small[n, :] + noise)\n",
    "\n",
    "signals_small_noise = np.array(signals_small_noise)\n",
    "    \n",
    "for n in range(signals_large.shape[0]):\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_large_noise.append(signals_large[n, :] + noise)\n",
    "    \n",
    "signals_large_noise = np.array(signals_large_noise)\n",
    "    \n",
    "fig, axs = plt.subplots(3, 2, figsize=(12,6), sharex=True, sharey=True)\n",
    "\n",
    "for m in range(2):\n",
    "    for n in range(3):\n",
    "        if m == 0:\n",
    "            axs[n, m].plot(time, np.real(signals_small_noise[n, :]), label = 'N=10, noise')\n",
    "            axs[n, m].plot(time, 20 * np.real(signals_small[n, :]), label = 'N=10, signal. Magnified 20x')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            axs[n, m].plot(time, np.real(signals_large_noise[n, :]), label = 'N=100, noise')\n",
    "            axs[n, m].plot(time, 50 * np.real(signals_large[n, :]), label = 'N=100, signal. Magnified 50x')\n",
    "            \n",
    "axs[0, 0].set_xlim(time[0], time[1000])\n",
    "#axs[0, 0].set_ylim(-1, 1)\n",
    "axs[0, 0].legend(loc = (0.4,1))\n",
    "axs[0, 1].legend(loc = (0.4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-burns",
   "metadata": {},
   "source": [
    "# Standard Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-satisfaction",
   "metadata": {},
   "source": [
    "## Sum signals and apply FFT. We observe that noise power scales as N. So the hypothetical array with more channels has worse SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sum = signals_small.sum(0)\n",
    "large_sum = signals_large.sum(0)\n",
    "\n",
    "small_sum_noise = signals_small_noise.sum(0)\n",
    "large_sum_noise = signals_large_noise.sum(0)\n",
    "\n",
    "small_sum_noise_fft = np.fft.fftshift(np.fft.fft(small_sum_noise) / num_samples)\n",
    "large_sum_noise_fft = np.fft.fftshift(np.fft.fft(large_sum_noise) / num_samples)\n",
    "\n",
    "small_sum_fft = np.fft.fftshift(np.fft.fft(small_sum) / num_samples)\n",
    "large_sum_fft = np.fft.fftshift(np.fft.fft(large_sum) / num_samples)\n",
    "f = np.fft.fftshift(np.fft.fftfreq(num_samples, dt))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16,6), sharey=True, sharex=True)\n",
    "\n",
    "axs[0].plot(f, abs(small_sum_noise_fft), label='Signal + Noise')\n",
    "axs[0].plot(f, abs(small_sum_fft), label = 'Signal')\n",
    "axs[0].legend(loc=0)\n",
    "axs[0].set_title('Small Channel Number')\n",
    "\n",
    "axs[1].plot(f, abs(large_sum_noise_fft), label='Signal + Noise')\n",
    "axs[1].plot(f, abs(large_sum_fft), label='Signal')\n",
    "axs[1].legend(loc=0)\n",
    "axs[1].set_title('Large Channel Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-ground",
   "metadata": {},
   "source": [
    "# Matched Filter Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-honey",
   "metadata": {},
   "source": [
    "## Compute the matched filter score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_signal_vector = signals_small.reshape(signals_small.size)\n",
    "large_signal_vector = signals_large.reshape(signals_large.size)\n",
    "\n",
    "norm_small = 1 / np.sqrt(np.vdot(small_signal_vector, small_signal_vector) / noise_variance).real\n",
    "norm_large = 1 / np.sqrt(np.vdot(large_signal_vector, large_signal_vector) / noise_variance).real\n",
    "\n",
    "#norm_small = norm_small.reshape((norm_small.size, 1)).repeat(signals_small.shape[1], axis = 1)\n",
    "\n",
    "#norm_large = 1 / np.sqrt((signals_large.conjugate() * signals_large).sum(1) / noise_variance)\n",
    "#norm_large = norm_large.reshape((norm_large.size, 1)).repeat(signals_large.shape[1], axis = 1)\n",
    "\n",
    "template_small = norm_small * small_signal_vector\n",
    "template_large = norm_large * large_signal_vector\n",
    "#print(norm_small)\n",
    "#print(norm_large)\n",
    "\n",
    "print(abs(np.vdot(small_signal_vector, template_small)), np.sqrt(10) * abs(np.vdot(large_signal_vector, template_large)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "timeseries_small_noise = signals_small_noise.reshape(signals_small_noise.size)\n",
    "timeseries_small = signals_small.reshape(signals_small.size)\n",
    "\n",
    "timeseries_small_sum = signals_small.sum(0)\n",
    "timeseries_small_noise_sum = signals_small_noise.sum(0)\n",
    "\n",
    "timeseries_large_noise = signals_large_noise.reshape(signals_large_noise.size)\n",
    "timeseries_large = signals_large.reshape(signals_large.size)\n",
    "\n",
    "timeseries_large_sum = signals_large.sum(0)\n",
    "timeseries_large_noise_sum = signals_large_noise.sum(0)\n",
    "\n",
    "small_conv_noise = abs(scipy.signal.fftconvolve(timeseries_small, timeseries_small_noise))\n",
    "large_conv_noise = abs(scipy.signal.fftconvolve(timeseries_large, timeseries_large_noise))\n",
    "\n",
    "small_conv_noise_sum = abs(scipy.signal.fftconvolve(timeseries_small_sum, timeseries_small_noise_sum))\n",
    "large_conv_noise_sum = abs(scipy.signal.fftconvolve(timeseries_large_sum, timeseries_large_noise_sum))\n",
    "\n",
    "fig1, axs = plt.subplots(1, 1, figsize=(8,4))\n",
    "axs.plot(small_conv_noise, label='Small Ch Number')\n",
    "axs.plot(large_conv_noise, label='Large Ch Number')\n",
    "axs.legend()\n",
    "\n",
    "fig1, axs = plt.subplots(1, 1, figsize=(8,4))\n",
    "axs.plot(small_conv_noise_sum, label='Small Ch Number')\n",
    "axs.plot(large_conv_noise_sum, label='Large Ch Number')\n",
    "axs.legend()\n",
    "\n",
    "\n",
    "\n",
    "noise_large = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_large)\n",
    "noise_large = noise_large[:, 0] + 1j * noise_large[:, 1]\n",
    "\n",
    "noise_small = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_small)\n",
    "noise_small = noise_small[:, 0] + 1j * noise_small[:, 1]\n",
    "\n",
    "noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "snr_large = abs(np.vdot(timeseries_large, timeseries_large_noise)) / abs(np.vdot(timeseries_large, noise_large) / timeseries_large.size)\n",
    "snr_small = abs(np.vdot(timeseries_small, timeseries_small_noise)) / abs(np.vdot(timeseries_small, noise_small) / timeseries_small.size)\n",
    "\n",
    "print(snr_small)\n",
    "print(snr_large)\n",
    "\n",
    "snr_large_sum = (abs(np.vdot(timeseries_large_sum, timeseries_large_noise_sum)) \n",
    "                 / abs(np.vdot(timeseries_large_sum, noise_large.reshape(num_ch_large, num_samples).sum(0))))\n",
    "snr_small_sum = (abs(np.vdot(timeseries_small_sum, timeseries_small_noise_sum)) \n",
    "                 / abs(np.vdot(timeseries_small_sum, noise_small.reshape(num_ch_small, num_samples).sum(0))))\n",
    "\n",
    "print(snr_small_sum)\n",
    "print(snr_large_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-combat",
   "metadata": {},
   "source": [
    "## Experiment - Compute Matched Filter SNR Few Channel Array and Many Channel Array (1 Long Time Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 1000\n",
    "small_snr = []\n",
    "large_snr = []\n",
    "\n",
    "for i in range(ntest):\n",
    "    \n",
    "    noise_large = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_large)\n",
    "    noise_large = noise_large[:, 0] + 1j * noise_large[:, 1]\n",
    "\n",
    "    noise_small = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_small)\n",
    "    noise_small = noise_small[:, 0] + 1j * noise_small[:, 1]\n",
    "    \n",
    "    signals_small_noise = []\n",
    "    for n in range(signals_small.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_small_noise.append(signals_small[n, :] + noise)\n",
    "\n",
    "    signals_small_noise = np.array(signals_small_noise)\n",
    "    timeseries_small_noise = signals_small_noise.reshape(signals_small_noise.size)\n",
    "    \n",
    "    signals_large_noise = []\n",
    "    for n in range(signals_large.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_large_noise.append(signals_large[n, :] + noise)\n",
    "    \n",
    "    signals_large_noise = np.array(signals_large_noise)\n",
    "    timeseries_large_noise = signals_large_noise.reshape(signals_large_noise.size)\n",
    "\n",
    "\n",
    "    # calculate SNR\n",
    "    # SNR = (template \\cdot signal) / (template \\cdot noise_expectation)\n",
    "    small_snr.append(abs(np.vdot(timeseries_small, timeseries_small_noise)) / abs(np.vdot(timeseries_small, noise_small)))\n",
    "    large_snr.append(abs(np.vdot(timeseries_large, timeseries_large_noise)) / abs(np.vdot(timeseries_large, noise_large)))\n",
    "    \n",
    "    if i % 50 == 49:\n",
    "        print('Done with %d' % (i + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(small_snr, bins = np.linspace(0, 30, 50), histtype = 'step', label = 'N=10')\n",
    "plt.hist(large_snr, bins = np.linspace(0, 30, 50), histtype = 'step', label = 'N=100')\n",
    "plt.xlim(0, 30)\n",
    "plt.legend(loc=0)\n",
    "plt.title('MF SNR for Array with Few Antennas and Many Antennas')\n",
    "plt.xlabel('MF SNR')\n",
    "\n",
    "print(np.mean(small_snr))\n",
    "print(np.mean(large_snr))\n",
    "\n",
    "print(np.mean(small_snr)/np.mean(large_snr), np.sqrt(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-laptop",
   "metadata": {},
   "source": [
    "##  Experiment - Compute Matched Filter SNR Few Channel Array and Many Channel Array (Sum Before MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 1000\n",
    "small_snr = []\n",
    "large_snr = []\n",
    "\n",
    "for i in range(ntest):\n",
    "    \n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_small_noise = []\n",
    "    for n in range(signals_small.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_small_noise.append(signals_small[n, :] + noise)\n",
    "\n",
    "    signals_small_noise = np.array(signals_small_noise)\n",
    "    timeseries_small_noise_sum = signals_small_noise.sum(0)\n",
    "    \n",
    "    signals_large_noise = []\n",
    "    for n in range(signals_large.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_large_noise.append(signals_large[n, :] + noise)\n",
    "    \n",
    "    signals_large_noise = np.array(signals_large_noise)\n",
    "    timeseries_large_noise_sum = signals_large_noise.sum(0)\n",
    "\n",
    "\n",
    "    # calculate SNR\n",
    "    # SNR = (template \\cdot signal) / (template \\cdot noise_expectation)\n",
    "    small_snr.append(abs(np.vdot(timeseries_small_sum, timeseries_small_noise_sum)) / abs(np.vdot(timeseries_small_sum, noise)))\n",
    "    large_snr.append(abs(np.vdot(timeseries_large_sum, timeseries_large_noise_sum)) / abs(np.vdot(timeseries_large_sum, noise)))\n",
    "    \n",
    "    if i % 50 == 49:\n",
    "        print('Done with %d' % (i + 1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
