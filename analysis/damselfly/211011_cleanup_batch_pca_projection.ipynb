{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import damselfly as df\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "import subprocess\n",
    "\n",
    "PATH = '/storage/home/adz6/group/project'\n",
    "RESULTPATH = os.path.join(PATH, 'results/damselfly')\n",
    "PLOTPATH = os.path.join(PATH, 'plots/damselfly')\n",
    "DATAPATH = os.path.join(PATH, 'damselfly/data/datasets')\n",
    "SIMDATAPATH = os.path.join(PATH, 'damselfly/data/sim_data')\n",
    "SCRIPTPATH = os.path.join(PATH, 'scripting/output/damselfly')\n",
    "\n",
    "\"\"\"\n",
    "Date: 6/25/2021\n",
    "Description: template\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def MakeTemplates(signals, var =  1.38e-23 * 10 * 50 * 200e6):\n",
    "    norm_mat = 1 / np.sqrt(var * np.diag(np.matmul(signals, signals.conjugate().T)))\n",
    "\n",
    "    templates = norm_mat.reshape((*norm_mat.shape, 1)).repeat(signals.shape[-1], axis=-1) * signals\n",
    "    \n",
    "    return templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(SCRIPTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_list = os.listdir(SCRIPTPATH)\n",
    "#dest_dir = os.path.join(SCRIPTPATH, '211011_pca_angle_subset_job_array_proj')\n",
    "\n",
    "\n",
    "#for file in file_list:\n",
    "#    for file2 in os.listdir(os.path.join(SCRIPTPATH, file)):\n",
    "#        try:\n",
    "#            fname = os.listdir(os.path.join(SCRIPTPATH, file, file2))[0]\n",
    "\n",
    "#            subprocess.run(['cp', os.path.join(os.path.join(SCRIPTPATH, file, file2, fname)), os.path.join(dest_dir, fname)])\n",
    "#        except:\n",
    "#            continue\n",
    "    #print(os.listdir(os.path.join(SCRIPTPATH, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d16af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = np.load(os.path.join(dest_dir, '0.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = os.path.join(SCRIPTPATH, '211013_pca_energy_subset_job_array_proj')\n",
    "\n",
    "print(len(os.listdir(dest_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ee1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(930):\n",
    "#    try:\n",
    "#        file_array = np.load(os.path.join(dest_dir, f'{i}.npz'))\n",
    "#    except:\n",
    "#        print(f'{i}.npz')\n",
    "        \n",
    "\n",
    "for i, file in enumerate(os.listdir(dest_dir)):\n",
    "    if i == 0:\n",
    "        file_array = np.load(os.path.join(dest_dir, f'{i}.npz'))\n",
    "        \n",
    "        train_data = np.zeros((file_array['train'].shape[0], file_array['train'].shape[1], len(os.listdir(dest_dir))), np.complex64)\n",
    "        val_data = np.zeros((file_array['val'].shape[0], file_array['val'].shape[1], len(os.listdir(dest_dir))), np.complex64)\n",
    "        test_data = np.zeros((file_array['test'].shape[0], file_array['test'].shape[1], len(os.listdir(dest_dir))), np.complex64)\n",
    "        \n",
    "        train_data[:, :, i] = file_array['train']\n",
    "        val_data[:, :, i] = file_array['val']\n",
    "        test_data[:, :, i] = file_array['test']\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            file_array = np.load(os.path.join(dest_dir, f'{i}.npz'))\n",
    "\n",
    "            train_data[:, :, i] = file_array['train']\n",
    "            val_data[:, :, i] = file_array['val']\n",
    "            test_data[:, :, i] = file_array['test']\n",
    "        except:\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(PATH, 'damselfly/data/datasets/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(train_data[0, 0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb404169",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5dataset = h5py.File(os.path.join(PATH, 'damselfly/data/datasets/', '211009_84_1d2sl4mt_pca_angle_range.h5'), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = h5dataset['train']['label'][:]\n",
    "val_label = h5dataset['val']['label'][:]\n",
    "test_label = h5dataset['test']['label'][:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ccf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[np.argwhere(train_label==1).squeeze(), :, :].shape\n",
    "flat_train_data = train_data[np.argwhere(train_label==1).squeeze(), :, :].reshape(105440, 2 * 930)\n",
    "flat_noise_data = train_data[np.argwhere(train_label==0).squeeze(), :, :].reshape(26360, 2 * 930)\n",
    "\n",
    "print(np.argwhere(abs(flat_train_data).mean(axis=1) > 4e-8).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(abs(flat_train_data).mean(axis=1), 32, histtype='step')\n",
    "hist = plt.hist(abs(flat_noise_data).mean(axis=1), 32, histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(abs(train_data[np.argwhere(train_label==1).squeeze(), 0, :]).mean(axis=(1)), 32, histtype='step')\n",
    "hist = plt.hist(abs(train_data[np.argwhere(train_label==1).squeeze(), 1, :]).mean(axis=(1)), 32, histtype='step')\n",
    "hist = plt.hist(abs(train_data[np.argwhere(train_label==0).squeeze(), 0, :]).mean(axis=(1)), histtype='step' )\n",
    "\n",
    "\n",
    "np.argwhere(abs(train_data[np.argwhere(train_label==1).squeeze(), 1, :]).mean(axis=(1)) > 4e-8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(abs(train_data[np.argwhere(train_label==1).squeeze(), 1, :]).mean(axis=(1)), 32)\n",
    "hist = plt.hist(abs(train_data[np.argwhere(train_label==0).squeeze(), 1, :]).mean(axis=(1)), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd5e0a",
   "metadata": {},
   "source": [
    "# save pca data as a dataset for DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newh5dataset = h5py.File(os.path.join(PATH, 'damselfly/data/datasets/', '211014_84_1d2sl4mt_pca_energy_range_projected_real_imag_abs_val_cnn.h5'), 'w')\n",
    "groups = ['train', 'test', 'val']\n",
    "labels = [train_label, test_label, val_label]\n",
    "for i, dataset in enumerate([train_data, test_data, val_data]):\n",
    "    \n",
    "    #new_dataset = np.zeros((dataset.shape[0], dataset.shape[1] * dataset.shape[2]))\n",
    "    new_dataset = np.zeros((dataset.shape[0], dataset.shape[1] * 3, dataset.shape[2]))\n",
    "    \n",
    "    for irow in range(dataset.shape[0]):\n",
    "        n = 0\n",
    "        for islice in range(dataset.shape[1]):\n",
    "            for k in range(3): # real, imag, abs loop\n",
    "                if k == 0:\n",
    "                    new_dataset[irow, n, :] = dataset[irow, islice, :].real\n",
    "                if k == 1:\n",
    "                    new_dataset[irow, n, :] = dataset[irow, islice, :].imag\n",
    "                if k == 2:\n",
    "                    new_dataset[irow, n, :] = abs(dataset[irow, islice, :])\n",
    "                n += 1\n",
    "            \n",
    "    newgroup = newh5dataset.create_group(groups[i])\n",
    "    newgroup.create_dataset('data', data=new_dataset)\n",
    "    newgroup.create_dataset('label', data=labels[i])\n",
    "    \n",
    "    print(groups[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053204f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newh5dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(PATH, 'damselfly/data/datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa3f807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
