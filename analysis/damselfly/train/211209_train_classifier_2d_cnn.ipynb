{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import damselfly as df\n",
    "import mayfly as mf\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "import json\n",
    "import time\n",
    "\n",
    "PATH = '/storage/home/adz6/group/project'\n",
    "RESULTPATH = os.path.join(PATH, 'results/damselfly')\n",
    "PLOTPATH = os.path.join(PATH, 'plots/damselfly')\n",
    "DATAPATH = os.path.join(PATH, 'datasets/data')\n",
    "#SIMDATAPATH = os.path.join(PATH, 'damselfly/data/sim_data')\n",
    "\n",
    "damselpath = '/storage/home/adz6/group/project/damselfly'\n",
    "\"\"\"\n",
    "Date: 6/25/2021\n",
    "Description: template\n",
    "\"\"\"\n",
    "\n",
    "def CalculateAccuracy(output, labels):\n",
    "\n",
    "    output_prob = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    most_likely_class = torch.argmax(output_prob, dim=1)\n",
    "\n",
    "    most_likely_class_matches_label = torch.as_tensor(most_likely_class == labels, dtype=torch.float)\n",
    "\n",
    "    return torch.mean(most_likely_class_matches_label)\n",
    "\n",
    "def AddNoiseToBatch2D(batch, var):\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    noise = rng.multivariate_normal([0, 0], np.eye(2) * var / 2, batch.shape[0] * batch.shape[2] * batch.shape[3])\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    #print(noise.shape)\n",
    "    #noise = noise.reshape((batch.shape[0], batch.shape[1], batch.shape[2]))\n",
    "    \n",
    "    batch[:, 0, :] += torch.tensor(noise.real.reshape(batch.shape[0], batch.shape[2], batch.shape[3]), dtype=torch.float)\n",
    "    batch[:, 1, :] += torch.tensor(noise.imag.reshape(batch.shape[0], batch.shape[2], batch.shape[3]), dtype=torch.float)\n",
    "    \n",
    "    return batch\n",
    "    \n",
    "def NormBatch(batch):\n",
    "    \n",
    "    #print(torch.max(batch[:, 0, :], -1, keepdim=True)[0])\n",
    "    \n",
    "    batch[:, 0, :, :] *= 1 / torch.max(abs(batch[:, 0, :, :]), -1, keepdim=True)[0]\n",
    "    batch[:, 1, :, :] *= 1 / torch.max(abs(batch[:, 1, :, :]), -1, keepdim=True)[0]\n",
    "    \n",
    "    return batch\n",
    "    \n",
    "\n",
    "def LoadDataArrays2D(datafilepath, train_noise_frac, val_noise_frac, noise_var):\n",
    "    \n",
    "    file = h5py.File(datafilepath, 'r')\n",
    "    \n",
    "    train_data_no_noise = file['train']['data'][:]\n",
    "    train_label = file['train']['label'][:]\n",
    "    \n",
    "    val_data_no_noise = file['val']['data'][:]\n",
    "    val_label = file['val']['label'][:]\n",
    "    \n",
    "    ninput_ch = train_data_no_noise.shape[1]\n",
    "    input_shape = (train_data_no_noise.shape[2], train_data_no_noise.shape[3])\n",
    "    \n",
    "    Ntrain_signals_with_noise = int(train_data_no_noise.shape[0] * (1 + 0.25)) # need to fix these\n",
    "    Nval_signals_with_noise = int(val_data_no_noise.shape[0] * (2)) # need to fix.\n",
    "    \n",
    "    train_data = np.concatenate(\n",
    "        (\n",
    "            train_data_no_noise, \n",
    "            np.zeros((Ntrain_signals_with_noise - train_data_no_noise.shape[0], ninput_ch, *input_shape),dtype=np.float32)\n",
    "        ),axis = 0, dtype=np.float32)\n",
    "    \n",
    "    train_label = np.int32(np.concatenate(\n",
    "        (\n",
    "            train_label, \n",
    "            np.zeros(Ntrain_signals_with_noise - train_data_no_noise.shape[0])\n",
    "        ),axis = 0))\n",
    "    \n",
    "    val_data = np.concatenate(\n",
    "        (\n",
    "            train_data_no_noise, \n",
    "            np.zeros((Nval_signals_with_noise - val_data_no_noise.shape[0], ninput_ch, *input_shape),dtype=np.float32)\n",
    "        ),axis = 0, dtype=np.float32)\n",
    "    \n",
    "    val_label = np.int32(np.concatenate(\n",
    "        (\n",
    "            val_label, \n",
    "            np.zeros(Nval_signals_with_noise - val_data_no_noise.shape[0])\n",
    "        ),axis = 0))\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return (torch.tensor(train_data, dtype = torch.float), torch.tensor(train_label, dtype = torch.long)), (torch.tensor(val_data, dtype = torch.float), torch.tensor(val_label, dtype = torch.long))\n",
    "\n",
    "def TrainModel2D(class_weights, datafilepath, savepath, train_noise_frac, val_noise_frac, noise_var, device, batchsize, learning_rate, model, epochs, ncopies_train, ncopies_val):\n",
    "    \n",
    "    class_weight_tensor = torch.tensor(\n",
    "                                class_weights,\n",
    "                                 device=device, dtype=torch.float\n",
    "                                )\n",
    "    \n",
    "    \n",
    "    if not os.path.isdir(savepath):\n",
    "        os.mkdir(savepath)\n",
    "        \n",
    "    if device == torch.device(\"cuda:0\"):\n",
    "        print('Model moved to GPU')\n",
    "        model.to(device)\n",
    "        \n",
    "    print('Loading data')\n",
    "    train_data, val_data = LoadDataArrays2D(datafilepath, train_noise_frac, val_noise_frac, noise_var)\n",
    "  \n",
    "    #print(train_data[0].shape, train_data[1].shape, val_data[0].shape, val_data[1].shape,)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "                                                    torch.utils.data.TensorDataset(train_data[0], train_data[1]),\n",
    "                                                    batchsize,\n",
    "                                                    shuffle=True, \n",
    "                                                    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "                                                    torch.utils.data.TensorDataset(val_data[0], val_data[1]),\n",
    "                                                    batchsize,\n",
    "                                                    shuffle=True,\n",
    "                                                    )\n",
    "    \n",
    "    # define loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight = class_weight_tensor, reduction = 'mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    sns.set_theme(context='paper', style='whitegrid')\n",
    "    \n",
    "    \n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_model = {}\n",
    "    print('Training Starting')\n",
    "    for ep in range(epochs):\n",
    "        #print(f'Starting epoch {ep + 1}')\n",
    "        for icopy in range(ncopies_train):\n",
    "            for batch, labels in train_dataloader:\n",
    "                \n",
    "                batch = AddNoiseToBatch2D(batch, noise_var)\n",
    "                batch = NormBatch(batch)\n",
    "                \n",
    "                #fig = plt.figure(figsize=(13, 8))\n",
    "                #ax = fig.add_subplot(1,1,1)\n",
    "                \n",
    "                #ax.plot(batch[0, 0, :])\n",
    "                #ax.plot(batch[0, 1, :])\n",
    "                \n",
    "                #plt.show()\n",
    "                #input()\n",
    "                \n",
    "                if device == torch.device(\"cuda:0\"):\n",
    "                    batch = batch.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = model(batch)\n",
    "\n",
    "                loss = criterion(output, labels) # loss computed using input as output\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                \n",
    "                acc = CalculateAccuracy(output, labels)\n",
    "                print(f'|  {ep + 1}  |  {np.round(loss.item(), 5)}  |  {np.round(acc.item(), 5)}  ')\n",
    "                \n",
    "                train_acc.append(acc.item())\n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            for icopy in range(ncopies_val):\n",
    "                val_acc_list = []\n",
    "                for batch, labels in val_dataloader:\n",
    "                    \n",
    "                    batch = AddNoiseToBatch2D(batch, noise_var)\n",
    "                    batch = NormBatch(batch)\n",
    "\n",
    "                    if device == torch.device(\"cuda:0\"):\n",
    "                        batch = batch.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                    val_out = model(batch)\n",
    "                    \n",
    "                    val_loss = criterion(val_out, labels)\n",
    "                    \n",
    "                    val_acc_list.append(CalculateAccuracy(val_out, labels).item())\n",
    "                val_acc.append(np.mean(val_acc_list))\n",
    "                \n",
    "                if np.mean(val_acc_list) > best_val_acc:\n",
    "                    best_val_acc = np.mean(val_acc_list)\n",
    "                    best_model = model.state_dict()\n",
    "                    torch.save(best_model, os.path.join(savepath, f'model.pth'))\n",
    "                    \n",
    "                np.savez(os.path.join(savepath, f'loss'), train_loss = train_loss, train_acc = train_acc, val_acc = val_acc)\n",
    "                    \n",
    "                    \n",
    "                print(f'Validation Accuracy = {np.round(np.mean(val_acc_list), 5)}')\n",
    "                \n",
    "    #return {'train_loss': train_loss, 'train_acc': train_acc, 'val_acc': val_acc}, best_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(DATAPATH, 'dl','pca'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc443e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(DATAPATH, 'dl', 'pca', '211209_dl_classification_84_25_2cm_slice1_sample2x8192_proj256x128.h5')\n",
    "file = h5py.File(filepath, 'r')\n",
    "\n",
    "#print(file['train'].keys())\n",
    "\n",
    "file.close()\n",
    "\n",
    "noise_var = 60 * 1.38e-23 * 200e6 * 10 * 50 / (2 * 8192) # summed noise in frequency space\n",
    "\n",
    "batchsize = 500\n",
    "epochs = 200\n",
    "ep_per_check = 1\n",
    "lr = 1e-4\n",
    "\n",
    "noise_frac_train = 0.2\n",
    "noise_frac_test = 0.5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc = 256\n",
    "conv_list = [\n",
    "    [\n",
    "        [2, 20, 20],\n",
    "        [20, 20, 20],\n",
    "        [(n_pc, 4), (n_pc, 4), (n_pc, 4)],\n",
    "        (1, 4)\n",
    "    ],\n",
    "    [\n",
    "        [20, 40, 40],\n",
    "        [40, 40, 40],\n",
    "        [(n_pc, 4), (n_pc, 4), (n_pc, 4)],\n",
    "        (1, 4)\n",
    "    ],\n",
    "    [\n",
    "        [40, 80, 80],\n",
    "        [80, 80, 80],\n",
    "        [(n_pc, 4), (n_pc, 4), (n_pc, 4)],\n",
    "        (1, 4)\n",
    "    ],\n",
    "]\n",
    "\n",
    "model_config_2d_cnn = {\n",
    "    'nclass': 2,\n",
    "    'nch': 2,\n",
    "    'conv': conv_list\n",
    "}\n",
    "\n",
    "input_shape = (256, 128)\n",
    "\n",
    "linear_list = [\n",
    "            [df.models.GetConv2DOutputSize(model_config_2d_cnn['conv'], model_config_2d_cnn['nch'], input_shape), 512],\n",
    "            [512, 256],\n",
    "            [0.5, 0.5]\n",
    "        ]\n",
    "\n",
    "model = df.models.DFCNN2D(\n",
    "    model_config_2d_cnn['nclass'], \n",
    "    model_config_2d_cnn['nch'], \n",
    "    model_config_2d_cnn['conv'], \n",
    "    linear_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e768dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = 211209\n",
    "train_name = '84_25_2cm_slice1_sample2x8192_10K_pca_proj256x128'\n",
    "\n",
    "savepath = os.path.join(RESULTPATH, 'dl', 'train', f'{train_date}_{train_name}')\n",
    "\n",
    "TrainModel2D([5., 1.], filepath, savepath, noise_frac_train, noise_frac_test, \n",
    "           noise_var, device, batchsize, lr, model, epochs, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24d479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
