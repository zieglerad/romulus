{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import damselfly as df\n",
    "import mayfly as mf\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "import json\n",
    "import time\n",
    "\n",
    "PATH = '/storage/home/adz6/group/project'\n",
    "RESULTPATH = os.path.join(PATH, 'results/damselfly')\n",
    "PLOTPATH = os.path.join(PATH, 'plots/damselfly')\n",
    "DATAPATH = os.path.join(PATH, 'datasets/data')\n",
    "#SIMDATAPATH = os.path.join(PATH, 'damselfly/data/sim_data')\n",
    "\n",
    "damselpath = '/storage/home/adz6/group/project/damselfly'\n",
    "\"\"\"\n",
    "Date: 6/25/2021\n",
    "Description: template\n",
    "\"\"\"\n",
    "\n",
    "## set up process groups ##\n",
    "\n",
    "def Setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    \n",
    "    torch.distributed.init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
    "    \n",
    "def Cleanup():\n",
    "    torch.distributed.destroy_process_group()\n",
    "    \n",
    "####\n",
    "\n",
    "## distributed training loop ##\n",
    "\n",
    "def RunTrainDist(fn, args):\n",
    "    torch.multiprocessing.spawn(fn, \n",
    "                               args=(args,),\n",
    "                               nprocs=args['world_size'],\n",
    "                               join=True)\n",
    "    \n",
    "# args = [world_size, class_weights, datafilepath, savepath, train_noise_frac, \n",
    "# val_noise_frac, noise_var, batchsize, learning_rate, model, epochs]\n",
    "\n",
    "def TrainDist(rank, args):\n",
    "    \n",
    "    torch.distributed.init_process_group(backend=\"nccl\", rank=rank, world_size=args['world_size'])\n",
    "    \n",
    "    toch.cuda.set_device(rank)\n",
    "    \n",
    "    model = args['model'].cuda(rank)\n",
    "    ddp_model = torch.nn.parallel.DistributedDataParallel(model, devices_ids=[rank])\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight = args['class_weights'], reduction = 'mean').cuda(rank)\n",
    "    optimizer = torch.optim.Adam(ddp_model.parameters(), lr = args['lr'])\n",
    "    \n",
    "    train_data, val_data = LoadDataArrays2D(args['datafilepath'], \n",
    "                                            args['train_noise_frac'], \n",
    "                                            args['val_noise_frac'], \n",
    "                                            args['noise_var']\n",
    "                                           )\n",
    "  \n",
    "    #print(train_data[0].shape, train_data[1].shape, val_data[0].shape, val_data[1].shape,)\n",
    "    \n",
    "    \n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        torch.utils.data.TensorDataset(train_data[0], train_data[1]), \n",
    "        num_replicas = args['world_size'],\n",
    "        rank = rank\n",
    "    )\n",
    "    \n",
    "    val_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        torch.utils.data.TensorDataset(val_data[0], val_data[1]), \n",
    "        num_replicas = args['world_size'],\n",
    "        rank = rank\n",
    "    )\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "                                                    dataset = torch.utils.data.TensorDataset(train_data[0], train_data[1]),\n",
    "                                                    batch_size = args['batchsize'],\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=0,\n",
    "                                                    pin_memory=True,\n",
    "                                                    sampler=train_sampler\n",
    "                                                    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "                                                    torch.utils.data.TensorDataset(val_data[0], val_data[1]),\n",
    "                                                    batch_size = args['batchsize'],\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=0,\n",
    "                                                    pin_memory=True,\n",
    "                                                    sampler=val_sampler\n",
    "                                                    )\n",
    "    \n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_model = {}\n",
    "    print('Training Starting')\n",
    "    for ep in range(args['epochs']):\n",
    "        \n",
    "        torch.distributed.barrier()\n",
    "        \n",
    "        #print(f'Starting epoch {ep + 1}')\n",
    "        for batch, labels in train_dataloader:\n",
    "\n",
    "            batch = AddNoiseToBatch2D(batch, args['noise_var'])\n",
    "            batch = NormBatch(batch)\n",
    "\n",
    "            batch = batch.cuda(rank)\n",
    "            labels = labels.cuda(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = ddp_model(batch)\n",
    "\n",
    "            loss = criterion(output, labels) # loss computed using input as output\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = CalculateAccuracy(output, labels)\n",
    "            print(f'|  {ep + 1}  |  {np.round(loss.item(), 5)}  |  {np.round(acc.item(), 5)}  ')\n",
    "\n",
    "            train_acc.append(acc.item())\n",
    "            train_loss.append(loss.item())\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            val_acc_list = []\n",
    "            for batch, labels in val_dataloader:\n",
    "\n",
    "                batch = AddNoiseToBatch2D(batch, args['noise_var'])\n",
    "                batch = NormBatch(batch)\n",
    "\n",
    "                #if device == torch.device(\"cuda:0\"):\n",
    "                batch = batch.cuda(rank)\n",
    "                labels = labels.cuda(rank)\n",
    "\n",
    "                val_out = model(batch)\n",
    "\n",
    "                val_loss = criterion(val_out, labels)\n",
    "\n",
    "                val_acc_list.append(CalculateAccuracy(val_out, labels).item())\n",
    "            val_acc.append(np.mean(val_acc_list))\n",
    "\n",
    "            #if np.mean(val_acc_list) > best_val_acc and rank == 0:\n",
    "            #    best_val_acc = np.mean(val_acc_list)\n",
    "            #    best_model = ddp_model.state_dict()\n",
    "            #    torch.save(best_model, os.path.join(savepath, f'model.pth'))\n",
    "\n",
    "            #np.savez(os.path.join(savepath, f'loss'), train_loss = train_loss, train_acc = train_acc, val_acc = val_acc)\n",
    "\n",
    "\n",
    "            print(f'Validation Accuracy = {np.round(np.mean(val_acc_list), 5)}')\n",
    "            \n",
    "    Cleanup()\n",
    "    \n",
    "\n",
    "\n",
    "def CalculateAccuracy(output, labels):\n",
    "\n",
    "    output_prob = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    most_likely_class = torch.argmax(output_prob, dim=1)\n",
    "\n",
    "    most_likely_class_matches_label = torch.as_tensor(most_likely_class == labels, dtype=torch.float)\n",
    "\n",
    "    return torch.mean(most_likely_class_matches_label)\n",
    "\n",
    "def AddNoiseToBatch2D(batch, var):\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    noise = rng.multivariate_normal([0, 0], np.eye(2) * var / 2, batch.shape[0] * batch.shape[2] * batch.shape[3])\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    #print(noise.shape)\n",
    "    #noise = noise.reshape((batch.shape[0], batch.shape[1], batch.shape[2]))\n",
    "    \n",
    "    batch[:, 0, :] += torch.tensor(noise.real.reshape(batch.shape[0], batch.shape[2], batch.shape[3]), dtype=torch.float)\n",
    "    batch[:, 1, :] += torch.tensor(noise.imag.reshape(batch.shape[0], batch.shape[2], batch.shape[3]), dtype=torch.float)\n",
    "    \n",
    "    return batch\n",
    "    \n",
    "def NormBatch(batch):\n",
    "    \n",
    "    #print(torch.max(batch[:, 0, :], -1, keepdim=True)[0])\n",
    "    \n",
    "    batch[:, 0, :, :] *= 1 / torch.max(abs(batch[:, 0, :, :]), -1, keepdim=True)[0]\n",
    "    batch[:, 1, :, :] *= 1 / torch.max(abs(batch[:, 1, :, :]), -1, keepdim=True)[0]\n",
    "    \n",
    "    return batch\n",
    "    \n",
    "\n",
    "def LoadDataArrays2D(datafilepath, train_noise_frac, val_noise_frac, noise_var):\n",
    "    \n",
    "    file = h5py.File(datafilepath, 'r')\n",
    "    \n",
    "    train_data_no_noise = file['train']['data'][:]\n",
    "    train_label = file['train']['label'][:]\n",
    "    \n",
    "    val_data_no_noise = file['val']['data'][:]\n",
    "    val_label = file['val']['label'][:]\n",
    "    \n",
    "    ninput_ch = train_data_no_noise.shape[1]\n",
    "    input_shape = (train_data_no_noise.shape[2], train_data_no_noise.shape[3])\n",
    "    \n",
    "    Ntrain_signals_with_noise = int(train_data_no_noise.shape[0] * (1 + 0.25)) # need to fix these\n",
    "    Nval_signals_with_noise = int(val_data_no_noise.shape[0] * (2)) # need to fix.\n",
    "    \n",
    "    train_data = np.concatenate(\n",
    "        (\n",
    "            train_data_no_noise, \n",
    "            np.zeros((Ntrain_signals_with_noise - train_data_no_noise.shape[0], ninput_ch, *input_shape),dtype=np.float32)\n",
    "        ),axis = 0, dtype=np.float32)\n",
    "    \n",
    "    train_label = np.int32(np.concatenate(\n",
    "        (\n",
    "            train_label, \n",
    "            np.zeros(Ntrain_signals_with_noise - train_data_no_noise.shape[0])\n",
    "        ),axis = 0))\n",
    "    \n",
    "    val_data = np.concatenate(\n",
    "        (\n",
    "            train_data_no_noise, \n",
    "            np.zeros((Nval_signals_with_noise - val_data_no_noise.shape[0], ninput_ch, *input_shape),dtype=np.float32)\n",
    "        ),axis = 0, dtype=np.float32)\n",
    "    \n",
    "    val_label = np.int32(np.concatenate(\n",
    "        (\n",
    "            val_label, \n",
    "            np.zeros(Nval_signals_with_noise - val_data_no_noise.shape[0])\n",
    "        ),axis = 0))\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return (torch.tensor(train_data, dtype = torch.float), torch.tensor(train_label, dtype = torch.long)), (torch.tensor(val_data, dtype = torch.float), torch.tensor(val_label, dtype = torch.long))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(DATAPATH, 'dl','pca'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc443e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(DATAPATH, 'dl', 'pca', '211209_dl_classification_84_25_2cm_slice1_sample2x8192_proj256x128.h5')\n",
    "file = h5py.File(filepath, 'r')\n",
    "\n",
    "#print(file['train'].keys())\n",
    "\n",
    "file.close()\n",
    "\n",
    "noise_var = 60 * 1.38e-23 * 200e6 * 10 * 50 / (2 * 8192) # summed noise in frequency space\n",
    "\n",
    "batchsize = 500\n",
    "epochs = 200\n",
    "ep_per_check = 1\n",
    "lr = 1e-4\n",
    "\n",
    "noise_frac_train = 0.2\n",
    "noise_frac_test = 0.5\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc = 256\n",
    "conv_list = [\n",
    "    [\n",
    "        [2, 20, 20],\n",
    "        [20, 20, 20],\n",
    "        [(n_pc, 4), (n_pc, 4), (n_pc, 4)],\n",
    "        (1, 4)\n",
    "    ],\n",
    "    [\n",
    "        [20, 40, 40],\n",
    "        [40, 40, 40],\n",
    "        [(n_pc, 4), (n_pc, 4), (n_pc, 4)],\n",
    "        (1, 4)\n",
    "    ],\n",
    "    [\n",
    "        [40, 80, 80],\n",
    "        [80, 80, 80],\n",
    "        [(n_pc, 4), (n_pc, 4), (n_pc, 4)],\n",
    "        (1, 4)\n",
    "    ],\n",
    "]\n",
    "\n",
    "model_config_2d_cnn = {\n",
    "    'nclass': 2,\n",
    "    'nch': 2,\n",
    "    'conv': conv_list\n",
    "}\n",
    "\n",
    "input_shape = (256, 128)\n",
    "\n",
    "linear_list = [\n",
    "            [df.models.GetConv2DOutputSize(model_config_2d_cnn['conv'], model_config_2d_cnn['nch'], input_shape), 512],\n",
    "            [512, 256],\n",
    "            [0.5, 0.5]\n",
    "        ]\n",
    "\n",
    "model = df.models.DFCNN2D(\n",
    "    model_config_2d_cnn['nclass'], \n",
    "    model_config_2d_cnn['nch'], \n",
    "    model_config_2d_cnn['conv'], \n",
    "    linear_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e768dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = 211209\n",
    "train_name = '84_25_2cm_slice1_sample2x8192_10K_pca_proj256x128'\n",
    "\n",
    "savepath = os.path.join(RESULTPATH, 'dl', 'train', f'{train_date}_{train_name}')\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "world_size = n_gpus\n",
    "\n",
    "\n",
    "args = {\n",
    "    'world_size': world_size, \n",
    "    'class_weights': [5., 1.],\n",
    "    'datafilepath': filepath,\n",
    "    'savepath': savepath,\n",
    "    'train_noise_frac': noise_frac_train,\n",
    "    'val_noise_frac': noise_frac_test,\n",
    "    'noise_var': noise_var,\n",
    "    'batchsize': batchsize, \n",
    "    'lr': lr,\n",
    "    'model': model,\n",
    "    'epochs': epochs,\n",
    "       }\n",
    "\n",
    "# args = [world_size, class_weights, datafilepath, savepath, train_noise_frac, \n",
    "# val_noise_frac, noise_var, batchsize, learning_rate, model, epochs]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    \n",
    "    torch.multiprocessing.spawn(TrainDist, \n",
    "                               args=(args,),\n",
    "                               nprocs=args['world_size'],\n",
    "                               join=True)\n",
    "\n",
    "    #RunTrainDist(TrainDist, args)\n",
    "\n",
    "#TrainModel2D([5., 1.], filepath, savepath, noise_frac_train, noise_frac_test, \n",
    "#           noise_var, device, batchsize, lr, model, epochs, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24d479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
