{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import damselfly as df\n",
    "import math\n",
    "from scipy import integrate\n",
    "\n",
    "home = Path.home()\n",
    "results = home/'group'/'project'/'results'\n",
    "snr_sweep = np.linspace(1, 10, 19)\n",
    "\n",
    "def LoadModel(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def LoadSignal(config):\n",
    "    \n",
    "    signal = np.load(config['data_path'])\n",
    "    \n",
    "    return torch.tensor(signal)\n",
    "\n",
    "def FFT(signal):\n",
    "\n",
    "    return torch.fft.fft(signal, dim=-1, norm='forward')\n",
    "\n",
    "def GenerateDataTensor(signal, config):\n",
    "\n",
    "    shape = (\n",
    "        signal.shape[0] + config['number_noise'],\n",
    "        config['number_channel'],\n",
    "        config['samples']\n",
    "        )\n",
    "\n",
    "    data = torch.zeros(shape, dtype=torch.float)\n",
    "\n",
    "    data[0:signal.shape[0], 0, :] = signal.real\n",
    "    data[0:signal.shape[0], 1, :] = signal.imag\n",
    "\n",
    "    return data\n",
    "\n",
    "def GenerateTargetTensor(config, signal):\n",
    "\n",
    "    labels = torch.zeros(\n",
    "        signal.shape[0] + config['number_noise'],\n",
    "        dtype=torch.long\n",
    "        )\n",
    "\n",
    "    labels[0:signal.shape[0]] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "def AddNoise(data, config):\n",
    "\n",
    "    shape = data.shape\n",
    "    \n",
    "    noise = torch.normal(\n",
    "        mean = 0,\n",
    "        std = math.sqrt(config['var'] / 2),\n",
    "        size = shape\n",
    "        )\n",
    "\n",
    "    return data + noise\n",
    "\n",
    "def NormBatch(batch):\n",
    "    \n",
    "    batch = batch / torch.max(torch.max(abs(batch), dim=2, keepdim=True)[0], dim=1, keepdim=True)[0]\n",
    "\n",
    "    return batch\n",
    "\n",
    "def RollBatch(batch):\n",
    "\n",
    "    roll_ints = torch.randint(0, 200, (batch.shape[0],)) # 200 bins is roughly 100 eV of BW at 1T for 200 MHz and 8192 samples\n",
    "    batch = torch.fft.fftshift(batch, dim=-1)\n",
    "    for i, roll in enumerate(roll_ints):\n",
    "        #print(roll)\n",
    "        batch[i, :, :] = torch.roll(batch[i, :, :], (roll.item(),), dims=-1) # roll in the positive freq. direction for lower energy\n",
    "\n",
    "    return batch\n",
    "\n",
    "def EvalModel(config):\n",
    "    \n",
    "    data = LoadSignal(config)\n",
    "    data = FFT(data)\n",
    "    data_tensor = GenerateDataTensor(data, config)\n",
    "    target = GenerateTargetTensor(config, data)\n",
    "    #print(data.shape, data_tensor.shape)\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(data_tensor, target)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        config['training']['batchsize'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('Found GPU')\n",
    "        model = LoadModel(\n",
    "            config['model'](\n",
    "                config['model_config']['nclass'],\n",
    "                config['model_config']['nch'],\n",
    "                config['model_config']['conv'],\n",
    "                config['model_config']['lin']\n",
    "            ),\n",
    "            config['saved_model']\n",
    "        ).cuda(0)\n",
    "        \n",
    "    else:\n",
    "        print('No GPU')\n",
    "        model = LoadModel(\n",
    "            config['model'](\n",
    "                config['model_config']['nclass'],\n",
    "                config['model_config']['nch'],\n",
    "                config['model_config']['conv'],\n",
    "                config['model_config']['lin']\n",
    "            ),\n",
    "            config['saved_model']\n",
    "        ).cpu()\n",
    "        \n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for ep in range(config['epochs']):\n",
    "            #batch_count = 0\n",
    "            for batch, labels in loader:\n",
    "                batch = RollBatch(batch)\n",
    "                batch = AddNoise(batch, config)\n",
    "                batch = NormBatch(batch)\n",
    "                label_list.extend(labels.numpy())\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    output = model(batch.cuda(0))\n",
    "                    output = output.cpu()\n",
    "                    #output = torch.nn.functional.softmax(output.cpu(), dim=1)\n",
    "                    output_list.extend(output.numpy())\n",
    "                else:\n",
    "                    output = model(batch)\n",
    "                    output = torch.nn.functional.softmax(output, dim=1)\n",
    "                    output_list.extend(output.numpy())\n",
    "\n",
    "                #batch_count += 1\n",
    "                print(ep + 1)\n",
    "\n",
    "    return np.array(output_list), np.array(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate((results/'machine_learning'/'dnn'/'triggering'/'loss'/'dense_grid').iterdir()): print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a58cf4",
   "metadata": {},
   "source": [
    "# plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results/'machine_learning'/'dnn'/'triggering'/'loss'/'dense_grid'\n",
    "\n",
    "sns.set_theme(context='talk')\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "loss_data = np.load(results/'220228_pitch87.0_rad1cm_fft'/'model_cnn_loss.npy')\n",
    "ax.plot(loss_data[:, 2])\n",
    "#for snr in [1.0, 2.0, 3.0, 5.0, 10.0]:\n",
    "#    loss_data = np.load(results/'machine_learning'/'dnn'/'triggering'/'loss'/'toy_sinusoid'/'220223_snr_sweep'/f'model_cnn_snr{snr}.npy')\n",
    "#    ax.plot(loss_data[:, 2], label=f'SNR = {snr}')\n",
    "#    #print(loss_data)\n",
    "    \n",
    "ax.set_xticks(np.linspace(1, 600, 6))\n",
    "ax.set_xticklabels(np.int32(np.linspace(1, 100, 6)))\n",
    "ax.set_xlabel('Training Epoch')\n",
    "ax.set_ylabel('Training Loss (AU)')\n",
    "ax.legend(loc=1)\n",
    "ax.set_title('Model Training Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "#name = '220224_model_train_loss_vs_snr.png'\n",
    "#save_path = Path.home()/'group'/'project'/'plots'/'machine_learning'/'dnn'/'triggering'/'toy_sinusoid'/name\n",
    "\n",
    "#plt.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a862f5",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_config = [\n",
    "                        [\n",
    "                            [2 * 1, 16, 16],\n",
    "                            [16, 16, 16],\n",
    "                            [32, 32, 32],\n",
    "                            [1, 1, 1], # dilation\n",
    "                            16, # maxpool \n",
    "                        ],\n",
    "                        [\n",
    "                            [16, 32, 32],\n",
    "                            [32, 32, 32],\n",
    "                            [16, 16, 16],\n",
    "                            [1, 1, 1],\n",
    "                            8\n",
    "                        ],\n",
    "                        [\n",
    "                            [32, 64, 64],\n",
    "                            [64, 64, 64],\n",
    "                            [8, 8, 8],\n",
    "                            [1, 1, 1],\n",
    "                            4\n",
    "                        ],\n",
    "                    ]\n",
    "\n",
    "config = {\n",
    "    'data_path': Path.home()/'group'/'project'/'datasets'/'data'/'bf'/'220301_dense_grid_87.0deg_1to4cm_random.npy',\n",
    "    'samples': 8192,\n",
    "    'sample_freq': 200e6,\n",
    "    'number_noise': 4000,\n",
    "    'number_channel': 2, # real, imag.\n",
    "    'var': 1.38e-23 * 50 * 60 * math.sqrt(60) * 200e6 * 10 / 8192,\n",
    "    'epochs': 20, # number of copies of the test data to analyze\n",
    "\n",
    "    'training': {\n",
    "        'batchsize': 2500,\n",
    "    },\n",
    "    \n",
    "    'model': df.models.DFCNN,\n",
    "    'saved_model': results/'machine_learning'/'dnn'/'triggering'/'models'/'dense_grid'/'220301_pitch87.0_rad1to4cm_fft_100epoch'/f'model_cnn.pt',\n",
    "    'model_config': {\n",
    "        'conv': conv_layer_config,\n",
    "        'nclass': 2,\n",
    "        'nch': 2,\n",
    "        'lin': [\n",
    "            [df.models.GetConv1DOutputSize(conv_layer_config, 2, 8192), 512, 256], # input dense layer sizes\n",
    "            [512, 256, 128], # output dense layer sizes\n",
    "            [0.0, 0.0, 0.0] # dropout\n",
    "            ],\n",
    "    },\n",
    "}\n",
    "\n",
    "output, target = EvalModel(config)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bcae2",
   "metadata": {},
   "source": [
    "# plot histograms of model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db50710",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snr = 2\n",
    "\n",
    "signal_inds = np.argwhere(target == 1).squeeze()\n",
    "noise_inds = np.argwhere(target == 0).squeeze()\n",
    "\n",
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "hist = ax.hist(output[signal_inds, 1], bins=128, density=True )\n",
    "hist = ax.hist(output[noise_inds, 1], bins=64, density=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a663bf3",
   "metadata": {},
   "source": [
    "# calculate pdf and cdf vs snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = np.linspace(-5, 15, 5001)\n",
    "\n",
    "pdf_sig = np.zeros(bins.size-1)\n",
    "pdf_noise = np.zeros(bins.size-1)\n",
    "\n",
    "cdf_sig = np.zeros(bins.size-1)\n",
    "cdf_noise = np.zeros(bins.size-1)\n",
    "\n",
    "        \n",
    "signal_inds = np.argwhere(target == 1).squeeze()\n",
    "noise_inds = np.argwhere(target == 0).squeeze()\n",
    "\n",
    "hist_sig = np.histogram(output[signal_inds, 1], bins=bins, density=True )\n",
    "hist_noise = np.histogram(output[noise_inds, 1], bins=bins, density=True )\n",
    "\n",
    "hist_sig = hist_sig[0], hist_sig[1][1:]\n",
    "hist_noise = hist_noise[0], hist_noise[1][1:]\n",
    "\n",
    "pdf_sig = hist_sig[0]\n",
    "pdf_noise = hist_noise[0]\n",
    "\n",
    "#print(hist)\n",
    "for j in range(len(bins)-1):\n",
    "    cdf_sig[j] = integrate.trapezoid(hist_sig[0][0:j+1], x=hist_sig[1][0:j+1])\n",
    "    cdf_noise[j] = integrate.trapezoid(hist_noise[0][0:j+1], x=hist_noise[1][0:j+1])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8382fa7",
   "metadata": {},
   "source": [
    "# save pdf and cdf vs snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d78839",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'pdf_and_cdf.npz'\n",
    "save = results/'machine_learning'/'dnn'/'triggering'/'eval_outputs'/'dense_grid'/'220228_pitch87.0_rad1cm_fft'/name\n",
    "\n",
    "np.savez(\n",
    "    save,\n",
    "    pdf_signal=pdf_sig,\n",
    "    pdf_noise=pdf_noise,\n",
    "    cdf_signal=cdf_sig, \n",
    "    cdf_noise=cdf_noise,\n",
    "    bins=bins[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[1:], cdf_noise[5, :])\n",
    "plt.plot(bins[1:], cdf_sig[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66403029",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[1:], pdf_noise[5, :])\n",
    "plt.plot(bins[1:], pdf_sig[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "#for i in np.arange(0, 18, 2):\n",
    "ax.plot(1-cdf_noise[:], 1-cdf_sig[:])\n",
    "    \n",
    "ax.plot(np.linspace(0, 1, 1001), np.linspace(0, 1, 1001), color='grey', linestyle='--')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1e-6, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(abs(1-cdf_noise[0] - 1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "select_fpr = 1e-3\n",
    "select_tpr_vs_snr = np.zeros(snr_sweep.size)\n",
    "for i in range(snr_sweep.size):\n",
    "    index_near_fpr = np.argmin(abs(1-cdf_noise[i, :] - select_fpr))\n",
    "    \n",
    "    select_tpr_vs_snr[i] = 1-cdf_sig[i, index_near_fpr]\n",
    "    \n",
    "    \n",
    "ax.plot(snr_sweep, select_tpr_vs_snr, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d793f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "for fpr in [1e-1, 1e-2, 1e-3, 1e-4]:\n",
    "    select_fpr = fpr\n",
    "    select_tpr_vs_snr = np.zeros(snr_sweep.size)\n",
    "    for i in range(snr_sweep.size):\n",
    "        index_near_fpr = np.argmin(abs(1-cdf_noise[i, :] - select_fpr))\n",
    "\n",
    "        select_tpr_vs_snr[i] = 1-cdf_sig[i, index_near_fpr]\n",
    "\n",
    "\n",
    "    ax.plot(snr_sweep, select_tpr_vs_snr, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e3c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
