{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import damselfly as df\n",
    "import math\n",
    "from scipy import integrate\n",
    "\n",
    "home = Path.home()\n",
    "results = home/'group'/'project'/'results'\n",
    "snr_sweep = np.linspace(1, 10, 19)\n",
    "\n",
    "def LoadModel(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def GenerateSinusoid(config):\n",
    "\n",
    "    t = torch.arange(0, config['samples'], 1) * 1 / config['sample_freq']\n",
    "\n",
    "    signal = 1 * torch.exp(1j * 2 * math.pi * t * config['freq'])\n",
    "\n",
    "    return signal\n",
    "\n",
    "def CalculateNoiseVar(signal, config):\n",
    "\n",
    "    var = torch.vdot(signal, signal) / config['snr'] ** 2\n",
    "\n",
    "    return var\n",
    "\n",
    "def GenerateDataTensor(signal, config):\n",
    "\n",
    "    shape = (\n",
    "        config['number_signals'] + config['number_noise'],\n",
    "        config['number_channel'],\n",
    "        config['samples']\n",
    "        )\n",
    "\n",
    "    data = torch.zeros(shape, dtype=torch.float)\n",
    "\n",
    "    data[0:config['number_signals'], 0, :] = signal.real\n",
    "    data[0:config['number_signals'], 1, :] = signal.imag\n",
    "\n",
    "    return data\n",
    "\n",
    "def GenerateTargetTensor(config):\n",
    "\n",
    "    labels = torch.zeros(\n",
    "        config['number_signals'] + config['number_noise'],\n",
    "        dtype=torch.long\n",
    "        )\n",
    "\n",
    "    labels[0:config['number_signals']] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "def AddNoise(data, signal, config):\n",
    "\n",
    "    shape = data.shape\n",
    "    \n",
    "    noise = torch.normal(\n",
    "        mean = 0,\n",
    "        std = math.sqrt(CalculateNoiseVar(signal, config) / 2),\n",
    "        size = shape\n",
    "        )\n",
    "\n",
    "    return data + noise\n",
    "\n",
    "def NormBatch(batch):\n",
    "    \n",
    "    #print(torch.max(batch[:, 0, :], -1, keepdim=True)[0])\n",
    "\n",
    "    for ich in range(batch.shape[1]):\n",
    "    \n",
    "        batch[:, ich, :] *= 1 / torch.max(abs(batch[:, ich, :]), -1, keepdim=True)[0]\n",
    "        #batch[:, 1, :] *= 1 / torch.max(abs(batch[:, 1, :]), -1, keepdim=True)[0]\n",
    "        \n",
    "    return batch  \n",
    "\n",
    "def EvalModel(config):\n",
    "\n",
    "    signal = GenerateSinusoid(config)\n",
    "\n",
    "    data = GenerateDataTensor(signal, config)\n",
    "    target = GenerateTargetTensor(config)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(data, target)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        config['training']['batchsize'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('Found GPU')\n",
    "        model = LoadModel(\n",
    "            config['model'](\n",
    "                config['model_config']['nclass'],\n",
    "                config['model_config']['nch'],\n",
    "                config['model_config']['conv'],\n",
    "                config['model_config']['lin']\n",
    "            ),\n",
    "            config['saved_model']\n",
    "        ).cuda(0)\n",
    "    else:\n",
    "        print('No GPU')\n",
    "        model = LoadModel(\n",
    "            config['model'](\n",
    "                config['model_config']['nclass'],\n",
    "                config['model_config']['nch'],\n",
    "                config['model_config']['conv'],\n",
    "                config['model_config']['lin']\n",
    "            ),\n",
    "            config['saved_model']\n",
    "        ).cpu()\n",
    "        \n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for batch, labels in loader:\n",
    "\n",
    "            batch = AddNoise(batch, signal, config)\n",
    "            batch = NormBatch(batch)\n",
    "            label_list.append(labels.numpy())\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                output = model(batch.cuda(0))\n",
    "                output = output.cpu()\n",
    "                #output = torch.nn.functional.softmax(output.cpu(), dim=1)\n",
    "                output_list.extend(output.numpy())\n",
    "            else:\n",
    "                output = model(batch)\n",
    "                output = torch.nn.functional.softmax(output, dim=1)\n",
    "                output_list.extend(output.numpy())\n",
    "            \n",
    "            batch_count += 1\n",
    "            print(batch_count)\n",
    "\n",
    "    return np.array(output_list), np.array(label_list).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a58cf4",
   "metadata": {},
   "source": [
    "# plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='talk')\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "for snr in [1.0, 2.0, 3.0, 5.0, 10.0]:\n",
    "    loss_data = np.load(results/'machine_learning'/'dnn'/'triggering'/'loss'/'toy_sinusoid'/'220223_snr_sweep'/f'model_cnn_snr{snr}.npy')\n",
    "    ax.plot(loss_data[:, 2], label=f'SNR = {snr}')\n",
    "    #print(loss_data)\n",
    "    \n",
    "ax.set_xticks(np.linspace(1, 1200, 7))\n",
    "ax.set_xticklabels(np.int32(np.linspace(1, 300, 7)))\n",
    "ax.set_xlabel('Training Epoch')\n",
    "ax.set_ylabel('Training Loss (AU)')\n",
    "ax.legend(loc=1)\n",
    "ax.set_title('Model Training Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "name = '220224_model_train_loss_vs_snr.png'\n",
    "save_path = Path.home()/'group'/'project'/'plots'/'machine_learning'/'dnn'/'triggering'/'toy_sinusoid'/name\n",
    "\n",
    "plt.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a862f5",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_config = [\n",
    "                        [\n",
    "                            [2 * 1, 16],\n",
    "                            [16, 16],\n",
    "                            [16, 16],\n",
    "                            [1, 1,], # dilation\n",
    "                            16\n",
    "                        ],\n",
    "                        [\n",
    "                            [16, 32,],\n",
    "                            [32, 32,],\n",
    "                            [8, 8,],\n",
    "                            [1, 1,],\n",
    "                            8\n",
    "                        ],\n",
    "                        [\n",
    "                            [32, 64,],\n",
    "                            [64, 64,],\n",
    "                            [4, 4,],\n",
    "                            [1, 1,],\n",
    "                            4\n",
    "                        ],\n",
    "                    ]\n",
    "\n",
    "config = {\n",
    "    'freq':50e6, # 0 to 100 MHz\n",
    "    'snr': 2, # mf snr\n",
    "    'samples': 8192,\n",
    "    'sample_freq': 200e6,\n",
    "    'number_signals': 20000,\n",
    "    'number_noise': 20000,\n",
    "    'number_channel': 2, # real, imag.\n",
    "\n",
    "    'training': {\n",
    "        'batchsize': 2500,\n",
    "    },\n",
    "    \n",
    "    'model': df.models.DFCNN,\n",
    "    'saved_model': results/'machine_learning'/'dnn'/'triggering'/'models'/'toy_sinusoid'/'220223_snr_sweep'/f'model_cnn_snr2.0.pt',\n",
    "    'model_config': {\n",
    "        'conv': conv_layer_config,\n",
    "        'nclass': 2,\n",
    "        'nch': 2,\n",
    "        'lin': [\n",
    "            [df.models.GetConv1DOutputSize(conv_layer_config, 2, 8192), 512, 256], # input dense layer sizes\n",
    "            [512, 256, 128], # output dense layer sizes\n",
    "            [0.0, 0.0, 0.0] # dropout\n",
    "            ],\n",
    "    },\n",
    "}\n",
    "\n",
    "output_list = []\n",
    "target_list = []\n",
    "for snr in snr_sweep:\n",
    "    print(snr)\n",
    "    config['snr'] = snr\n",
    "    config['saved_model'] = results/'machine_learning'/'dnn'/'triggering'/'models'/'toy_sinusoid'/'220223_snr_sweep'/f'model_cnn_snr{snr}.pt'\n",
    "    \n",
    "    output, target = EvalModel(config)\n",
    "    \n",
    "    output_list.append(output)\n",
    "    target_list.append(target)\n",
    "    \n",
    "output = np.array(output_list)\n",
    "target = np.array(target_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bcae2",
   "metadata": {},
   "source": [
    "# plot histograms of model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snr = 2\n",
    "\n",
    "signal_inds = np.argwhere(target[0, :] == 1).squeeze()\n",
    "noise_inds = np.argwhere(target[0, :] == 0).squeeze()\n",
    "\n",
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "hist = ax.hist(output[n_snr, signal_inds, 1], bins=100, density=True )\n",
    "hist = ax.hist(output[n_snr, noise_inds, 1], bins=100, density=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a663bf3",
   "metadata": {},
   "source": [
    "# calculate pdf and cdf vs snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = np.linspace(-30, 30, 25001)\n",
    "\n",
    "pdf_sig = np.zeros((snr_sweep.size, bins.size-1))\n",
    "pdf_noise = np.zeros((snr_sweep.size, bins.size-1))\n",
    "\n",
    "cdf_sig = np.zeros((snr_sweep.size, bins.size-1))\n",
    "cdf_noise = np.zeros((snr_sweep.size, bins.size-1))\n",
    "\n",
    "for i in range(len(snr_sweep)):\n",
    "    print(i)\n",
    "    #if i > 2:\n",
    "    #    continue\n",
    "        \n",
    "    signal_inds = np.argwhere(target[i, :] == 1).squeeze()\n",
    "    noise_inds = np.argwhere(target[i, :] == 0).squeeze()\n",
    "    \n",
    "    hist_sig = np.histogram(output[i, signal_inds, 1], bins=bins, density=True )\n",
    "    hist_noise = np.histogram(output[i, noise_inds, 1], bins=bins, density=True )\n",
    "    \n",
    "    hist_sig = hist_sig[0], hist_sig[1][1:]\n",
    "    hist_noise = hist_noise[0], hist_noise[1][1:]\n",
    "    \n",
    "    pdf_sig[i, :] = hist_sig[0]\n",
    "    pdf_noise[i, :] = hist_noise[0]\n",
    "\n",
    "    #print(hist)\n",
    "    for j in range(len(bins)-1):\n",
    "        #if j % 250 == 249:\n",
    "        #    print(j+1)\n",
    "        cdf_sig[i, j] = integrate.trapezoid(hist_sig[0][0:j+1], x=hist_sig[1][0:j+1])\n",
    "        cdf_noise[i, j] = integrate.trapezoid(hist_noise[0][0:j+1], x=hist_noise[1][0:j+1])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8382fa7",
   "metadata": {},
   "source": [
    "# save pdf and cdf vs snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d78839",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '220224_cnn_pdf_and_cdf_vs_snr.npz'\n",
    "save = results/'machine_learning'/'dnn'/'triggering'/'eval_outputs'/'toy_sinusoid'/'220223_snr_sweep'/name\n",
    "\n",
    "np.savez(\n",
    "    save,\n",
    "    pdf_signal=pdf_sig,\n",
    "    pdf_noise=pdf_noise,\n",
    "    cdf_signal=cdf_sig, \n",
    "    cdf_noise=cdf_noise,\n",
    "    bins=bins[1:],\n",
    "    snr=snr_sweep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[1:], cdf_noise[5, :])\n",
    "plt.plot(bins[1:], cdf_sig[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66403029",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[1:], pdf_noise[5, :])\n",
    "plt.plot(bins[1:], pdf_sig[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "for i in np.arange(0, 18, 2):\n",
    "    ax.plot(1-cdf_noise[i, :], 1-cdf_sig[i, :])\n",
    "    \n",
    "ax.plot(np.linspace(0, 1, 1001), np.linspace(0, 1, 1001), color='grey', linestyle='--')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1e-6, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(abs(1-cdf_noise[0] - 1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "select_fpr = 1e-3\n",
    "select_tpr_vs_snr = np.zeros(snr_sweep.size)\n",
    "for i in range(snr_sweep.size):\n",
    "    index_near_fpr = np.argmin(abs(1-cdf_noise[i, :] - select_fpr))\n",
    "    \n",
    "    select_tpr_vs_snr[i] = 1-cdf_sig[i, index_near_fpr]\n",
    "    \n",
    "    \n",
    "ax.plot(snr_sweep, select_tpr_vs_snr, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d793f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "for fpr in [1e-1, 1e-2, 1e-3, 1e-4]:\n",
    "    select_fpr = fpr\n",
    "    select_tpr_vs_snr = np.zeros(snr_sweep.size)\n",
    "    for i in range(snr_sweep.size):\n",
    "        index_near_fpr = np.argmin(abs(1-cdf_noise[i, :] - select_fpr))\n",
    "\n",
    "        select_tpr_vs_snr[i] = 1-cdf_sig[i, index_near_fpr]\n",
    "\n",
    "\n",
    "    ax.plot(snr_sweep, select_tpr_vs_snr, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e3c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
