{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-improvement",
   "metadata": {},
   "source": [
    "# Define Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-harvest",
   "metadata": {},
   "source": [
    "## Basic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample period \n",
    "dt = 2e-9 # 2ns <-> 500 MHz\n",
    "\n",
    "# number of samples\n",
    "num_samples = 8192\n",
    "\n",
    "# time\n",
    "time = np.arange(0, 8192, 1) * dt\n",
    "\n",
    "# signal power\n",
    "power = 1\n",
    "\n",
    "# small channel number\n",
    "num_ch_small = 10\n",
    "\n",
    "# large channel number\n",
    "num_ch_large = 100\n",
    "\n",
    "# noise_variance\n",
    "noise_variance = 2e1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-journalism",
   "metadata": {},
   "source": [
    "## Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amplitude\n",
    "amplitude = np.sqrt(power)\n",
    "\n",
    "# frequency\n",
    "freq = 25e6\n",
    "\n",
    "signal = amplitude * np.exp(-1j * 2 * np.pi * freq * time) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-partner",
   "metadata": {},
   "source": [
    "## Small Channel Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_small = []\n",
    "\n",
    "for n in range(num_ch_small):\n",
    "    \n",
    "    #noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    #noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_small.append(signal * 1 / np.sqrt(num_ch_small))\n",
    "    \n",
    "signals_small = np.array(signals_small)\n",
    "\n",
    "(signals_small.conjugate() * signals_small).sum(0).sum(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-angle",
   "metadata": {},
   "source": [
    "## Large Channel Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_large = []\n",
    "\n",
    "for n in range(num_ch_large):\n",
    "    \n",
    "    #noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    #noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_large.append(signal * 1 / num_ch_large)\n",
    "    \n",
    "signals_large = np.array(signals_large)\n",
    "\n",
    "abs(np.mean(np.sum(signals_large, axis = 0).conjugate() * np.sum(signals_large, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-spirit",
   "metadata": {},
   "source": [
    "# Compare Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-covering",
   "metadata": {},
   "source": [
    "## Hypothetical array that collects the same power with different numbers of antennas. The amplitudes of signals in the array with more channels are smaller relative to the array with fewer antennas. e.g. An array with few high gain antennas or an array with many low gain antennas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power = <signal^H * signal>\n",
    "pow_small = abs(np.mean(np.sum(signals_small, axis = 0).conjugate() * np.sum(signals_small, axis = 0)))\n",
    "pow_large = abs(np.mean(np.sum(signals_large, axis = 0).conjugate() * np.sum(signals_large, axis = 0)))\n",
    "\n",
    "print('Total power from array with small channel number: %.2f' % pow_small)\n",
    "print('Total power from array with large channel number: %.2f' % pow_large)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12,6), sharex=True, sharey=True)\n",
    "\n",
    "for m in range(2):\n",
    "    for n in range(3):\n",
    "        if m == 0:\n",
    "            axs[n, m].plot(time, np.real(signals_small[n, :]), label = 'N=10')\n",
    "            \n",
    "        else:\n",
    "            axs[n, m].plot(time, np.real(signals_large[n, :]), label = 'N=100')\n",
    "axs[0, 0].set_xlim(time[0], time[200])\n",
    "axs[0, 0].legend(loc = (0.4,1))\n",
    "axs[0, 1].legend(loc = (0.4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-elephant",
   "metadata": {},
   "source": [
    "## Add independent WGN to each channel. The array with many channels has lower SNR per channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_small_noise = []\n",
    "signals_large_noise = []\n",
    "\n",
    "for n in range(signals_small.shape[0]):\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_small_noise.append(signals_small[n, :] + noise)\n",
    "\n",
    "signals_small_noise = np.array(signals_small_noise)\n",
    "    \n",
    "for n in range(signals_large.shape[0]):\n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_large_noise.append(signals_large[n, :] + noise)\n",
    "    \n",
    "signals_large_noise = np.array(signals_large_noise)\n",
    "    \n",
    "fig, axs = plt.subplots(3, 2, figsize=(12,6), sharex=True, sharey=True)\n",
    "\n",
    "for m in range(2):\n",
    "    for n in range(3):\n",
    "        if m == 0:\n",
    "            axs[n, m].plot(time, np.real(signals_small_noise[n, :]), label = 'N=10, noise')\n",
    "            axs[n, m].plot(time, 20 * np.real(signals_small[n, :]), label = 'N=10, signal. Magnified 20x')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            axs[n, m].plot(time, np.real(signals_large_noise[n, :]), label = 'N=100, noise')\n",
    "            axs[n, m].plot(time, 50 * np.real(signals_large[n, :]), label = 'N=100, signal. Magnified 50x')\n",
    "            \n",
    "axs[0, 0].set_xlim(time[0], time[1000])\n",
    "#axs[0, 0].set_ylim(-1, 1)\n",
    "axs[0, 0].legend(loc = (0.4,1))\n",
    "axs[0, 1].legend(loc = (0.4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-burns",
   "metadata": {},
   "source": [
    "# Standard Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-satisfaction",
   "metadata": {},
   "source": [
    "## Sum signals and apply FFT. We observe that noise power scales as N. So the hypothetical array with more channels has worse SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sum = signals_small.sum(0)\n",
    "large_sum = signals_large.sum(0)\n",
    "\n",
    "small_sum_noise = signals_small_noise.sum(0)\n",
    "large_sum_noise = signals_large_noise.sum(0)\n",
    "\n",
    "small_sum_noise_fft = np.fft.fftshift(np.fft.fft(small_sum_noise) / num_samples)\n",
    "large_sum_noise_fft = np.fft.fftshift(np.fft.fft(large_sum_noise) / num_samples)\n",
    "\n",
    "small_sum_fft = np.fft.fftshift(np.fft.fft(small_sum) / num_samples)\n",
    "large_sum_fft = np.fft.fftshift(np.fft.fft(large_sum) / num_samples)\n",
    "f = np.fft.fftshift(np.fft.fftfreq(num_samples, dt))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16,6), sharey=True, sharex=True)\n",
    "\n",
    "axs[0].plot(f, abs(small_sum_noise_fft), label='Signal + Noise')\n",
    "axs[0].plot(f, abs(small_sum_fft), label = 'Signal')\n",
    "axs[0].legend(loc=0)\n",
    "axs[0].set_title('Small Channel Number')\n",
    "\n",
    "axs[1].plot(f, abs(large_sum_noise_fft), label='Signal + Noise')\n",
    "axs[1].plot(f, abs(large_sum_fft), label='Signal')\n",
    "axs[1].legend(loc=0)\n",
    "axs[1].set_title('Large Channel Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-ground",
   "metadata": {},
   "source": [
    "# Matched Filter Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-honey",
   "metadata": {},
   "source": [
    "## Compute the matched filter score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_signal_vector = signals_small.reshape(signals_small.size)\n",
    "large_signal_vector = signals_large.reshape(signals_large.size)\n",
    "\n",
    "norm_small = 1 / np.sqrt(np.vdot(small_signal_vector, small_signal_vector) / noise_variance).real\n",
    "norm_large = 1 / np.sqrt(np.vdot(large_signal_vector, large_signal_vector) / noise_variance).real\n",
    "\n",
    "#norm_small = norm_small.reshape((norm_small.size, 1)).repeat(signals_small.shape[1], axis = 1)\n",
    "\n",
    "#norm_large = 1 / np.sqrt((signals_large.conjugate() * signals_large).sum(1) / noise_variance)\n",
    "#norm_large = norm_large.reshape((norm_large.size, 1)).repeat(signals_large.shape[1], axis = 1)\n",
    "\n",
    "template_small = norm_small * small_signal_vector\n",
    "template_large = norm_large * large_signal_vector\n",
    "#print(norm_small)\n",
    "#print(norm_large)\n",
    "\n",
    "print(abs(np.vdot(small_signal_vector, template_small)), np.sqrt(10) * abs(np.vdot(large_signal_vector, template_large)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "timeseries_small_noise = signals_small_noise.reshape(signals_small_noise.size)\n",
    "timeseries_small = signals_small.reshape(signals_small.size)\n",
    "\n",
    "timeseries_small_sum = signals_small.sum(0)\n",
    "timeseries_small_noise_sum = signals_small_noise.sum(0)\n",
    "\n",
    "timeseries_large_noise = signals_large_noise.reshape(signals_large_noise.size)\n",
    "timeseries_large = signals_large.reshape(signals_large.size)\n",
    "\n",
    "timeseries_large_sum = signals_large.sum(0)\n",
    "timeseries_large_noise_sum = signals_large_noise.sum(0)\n",
    "\n",
    "small_conv_noise = abs(scipy.signal.fftconvolve(timeseries_small, timeseries_small_noise))\n",
    "large_conv_noise = abs(scipy.signal.fftconvolve(timeseries_large, timeseries_large_noise))\n",
    "\n",
    "small_conv_noise_sum = abs(scipy.signal.fftconvolve(timeseries_small_sum, timeseries_small_noise_sum))\n",
    "large_conv_noise_sum = abs(scipy.signal.fftconvolve(timeseries_large_sum, timeseries_large_noise_sum))\n",
    "\n",
    "fig1, axs = plt.subplots(1, 1, figsize=(8,4))\n",
    "axs.plot(small_conv_noise, label='Small Ch Number')\n",
    "axs.plot(large_conv_noise, label='Large Ch Number')\n",
    "axs.legend()\n",
    "\n",
    "fig1, axs = plt.subplots(1, 1, figsize=(8,4))\n",
    "axs.plot(small_conv_noise_sum, label='Small Ch Number')\n",
    "axs.plot(large_conv_noise_sum, label='Large Ch Number')\n",
    "axs.legend()\n",
    "\n",
    "\n",
    "\n",
    "noise_large = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_large)\n",
    "noise_large = noise_large[:, 0] + 1j * noise_large[:, 1]\n",
    "\n",
    "noise_small = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_small)\n",
    "noise_small = noise_small[:, 0] + 1j * noise_small[:, 1]\n",
    "\n",
    "noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "snr_large = abs(np.vdot(timeseries_large, timeseries_large_noise)) / abs(np.vdot(timeseries_large, noise_large) / timeseries_large.size)\n",
    "snr_small = abs(np.vdot(timeseries_small, timeseries_small_noise)) / abs(np.vdot(timeseries_small, noise_small) / timeseries_small.size)\n",
    "\n",
    "print(snr_small)\n",
    "print(snr_large)\n",
    "\n",
    "snr_large_sum = (abs(np.vdot(timeseries_large_sum, timeseries_large_noise_sum)) \n",
    "                 / abs(np.vdot(timeseries_large_sum, noise_large.reshape(num_ch_large, num_samples).sum(0))))\n",
    "snr_small_sum = (abs(np.vdot(timeseries_small_sum, timeseries_small_noise_sum)) \n",
    "                 / abs(np.vdot(timeseries_small_sum, noise_small.reshape(num_ch_small, num_samples).sum(0))))\n",
    "\n",
    "print(snr_small_sum)\n",
    "print(snr_large_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-combat",
   "metadata": {},
   "source": [
    "## Experiment - Compute Matched Filter SNR Few Channel Array and Many Channel Array (1 Long Time Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 1000\n",
    "small_snr = []\n",
    "large_snr = []\n",
    "\n",
    "for i in range(ntest):\n",
    "    \n",
    "    noise_large = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_large)\n",
    "    noise_large = noise_large[:, 0] + 1j * noise_large[:, 1]\n",
    "\n",
    "    noise_small = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples * num_ch_small)\n",
    "    noise_small = noise_small[:, 0] + 1j * noise_small[:, 1]\n",
    "    \n",
    "    signals_small_noise = []\n",
    "    for n in range(signals_small.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_small_noise.append(signals_small[n, :] + noise)\n",
    "\n",
    "    signals_small_noise = np.array(signals_small_noise)\n",
    "    timeseries_small_noise = signals_small_noise.reshape(signals_small_noise.size)\n",
    "    \n",
    "    signals_large_noise = []\n",
    "    for n in range(signals_large.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_large_noise.append(signals_large[n, :] + noise)\n",
    "    \n",
    "    signals_large_noise = np.array(signals_large_noise)\n",
    "    timeseries_large_noise = signals_large_noise.reshape(signals_large_noise.size)\n",
    "\n",
    "\n",
    "    # calculate SNR\n",
    "    # SNR = (template \\cdot signal) / (template \\cdot noise_expectation)\n",
    "    small_snr.append(abs(np.vdot(timeseries_small, timeseries_small_noise)) / abs(np.vdot(timeseries_small, noise_small)))\n",
    "    large_snr.append(abs(np.vdot(timeseries_large, timeseries_large_noise)) / abs(np.vdot(timeseries_large, noise_large)))\n",
    "    \n",
    "    if i % 50 == 49:\n",
    "        print('Done with %d' % (i + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(small_snr, bins = np.linspace(0, 30, 50), histtype = 'step', label = 'N=10')\n",
    "plt.hist(large_snr, bins = np.linspace(0, 30, 50), histtype = 'step', label = 'N=100')\n",
    "plt.xlim(0, 30)\n",
    "plt.legend(loc=0)\n",
    "plt.title('MF SNR for Array with Few Antennas and Many Antennas')\n",
    "plt.xlabel('MF SNR')\n",
    "\n",
    "print(np.mean(small_snr))\n",
    "print(np.mean(large_snr))\n",
    "\n",
    "print(np.mean(small_snr)/np.mean(large_snr), np.sqrt(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-laptop",
   "metadata": {},
   "source": [
    "##  Experiment - Compute Matched Filter SNR Few Channel Array and Many Channel Array (Sum Before MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 1000\n",
    "small_snr = []\n",
    "large_snr = []\n",
    "\n",
    "for i in range(ntest):\n",
    "    \n",
    "    noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "    noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "    \n",
    "    signals_small_noise = []\n",
    "    for n in range(signals_small.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_small_noise.append(signals_small[n, :] + noise)\n",
    "\n",
    "    signals_small_noise = np.array(signals_small_noise)\n",
    "    timeseries_small_noise_sum = signals_small_noise.sum(0)\n",
    "    \n",
    "    signals_large_noise = []\n",
    "    for n in range(signals_large.shape[0]):\n",
    "        noise = np.random.multivariate_normal([0, 0], np.eye(2) * noise_variance / 2, num_samples)\n",
    "        noise = noise[:, 0] + 1j * noise[:, 1]\n",
    "\n",
    "        signals_large_noise.append(signals_large[n, :] + noise)\n",
    "    \n",
    "    signals_large_noise = np.array(signals_large_noise)\n",
    "    timeseries_large_noise_sum = signals_large_noise.sum(0)\n",
    "\n",
    "\n",
    "    # calculate SNR\n",
    "    # SNR = (template \\cdot signal) / (template \\cdot noise_expectation)\n",
    "    small_snr.append(abs(np.vdot(timeseries_small_sum, timeseries_small_noise_sum)) / abs(np.vdot(timeseries_small_sum, noise)))\n",
    "    large_snr.append(abs(np.vdot(timeseries_large_sum, timeseries_large_noise_sum)) / abs(np.vdot(timeseries_large_sum, noise)))\n",
    "    \n",
    "    if i % 50 == 49:\n",
    "        print('Done with %d' % (i + 1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
